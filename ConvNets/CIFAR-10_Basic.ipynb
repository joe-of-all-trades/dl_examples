{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll build a simple convolutional neural network for CIFAR-10 image classification. Code contained in this project was based on Tensorflow 1.2.1 and python 3.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import time\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 6:\n",
      "Image - Min Value: 7 Max Value: 249\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f975a075a58>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 6\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return ( x - x.min() ) / ( x.max() - x.min() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    output = np.zeros([len(x), 10])\n",
    "    for idx, item in enumerate(x):\n",
    "        output[idx, item] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above function is equivalent to tf.one_hot(x, 10), but tensorflow module can not be pickled so we're sticking with the above implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "We will randomly shuffle the data, normalize them and save them in binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The above work is all saved so when we're revisiting this notebook we don't have to do those work again. We can start from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import helper\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "batch_mean = np.mean(valid_features)\n",
    "batch_std = np.std(valid_features)\n",
    "valid_features = valid_features.astype(np.float32)\n",
    "for ii in range(valid_features.shape[0]):\n",
    "    valid_features[ii, :, :, :] = (valid_features[ii, :, :, :] - batch_mean) / batch_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, None, \"keep_prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x_tensor, conv_num_outputs, conv_ksize, conv_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\", shape=[conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[3], conv_num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.Variable(tf.truncated_normal([conv_num_outputs], mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    \n",
    "    wc = tf.nn.conv2d(x_tensor, w, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    z = tf.nn.bias_add(wc, b)\n",
    "    \n",
    "    return tf.nn.relu(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten layer\n",
    "Implement the flatten function to change the dimension of x_tensor from a 4-D tensor to a 2-D tensor. The output should be the shape (Batch Size, Flattened Image Size). Shortcut option: you can use classes from the TensorFlow Layers or TensorFlow Layers (contrib) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # reference : https://github.com/tensorflow/tensorflow/issues/7253\n",
    "    return tf.reshape(x_tensor, [tf.shape(x_tensor)[0], np.prod(x_tensor.get_shape().as_list()[1:])])\n",
    "    \n",
    "    # This also works\n",
    "    #return tf.reshape(x_tensor, [-1, np.prod(x_tensor.shape[1:]).value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    fc = tf.reshape(x_tensor, [-1, np.prod(x_tensor.get_shape().as_list()[1:])])\n",
    "    \n",
    "    w = tf.get_variable(\"w\", shape=[np.prod(x_tensor.get_shape().as_list()[1:]), num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.Variable(tf.truncated_normal([num_outputs],mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    z = tf.add(tf.matmul(fc, w), b)\n",
    "    \n",
    "    return tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\", shape=[np.prod(x_tensor.get_shape().as_list()[1:]), num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.Variable(tf.truncated_normal([num_outputs],mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    return tf.add(tf.matmul(x_tensor, w), b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # Convolution and maxpooling layers\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        conv1 = conv2d(x, 40, (3, 3), (1, 1))\n",
    "        \n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        conv2 = conv2d(conv1, 80, (3, 3), (1, 1))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    \n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        conv3 = conv2d(conv2, 160, (3, 3), (1, 1))\n",
    "    \n",
    "    with tf.variable_scope(\"conv4\"):\n",
    "        conv4 = conv2d(conv3, 320, (3, 3), (1, 1))\n",
    "    conv4 = tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv4 = tf.nn.dropout(conv4, keep_prob)\n",
    "    \n",
    "    # Flatten Layer\n",
    "    f = flatten(conv4)\n",
    "\n",
    "    # Fully Connected layers\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "        fc1 = fully_conn(f, 512)\n",
    "        fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "        fc2 = fully_conn(fc1, 256)\n",
    "        fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # Output Layer\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        o = output(fc2, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(epsilon=1e-04).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Stats\n",
    "It's important to evaluate the performance of model once in a while. If effect, we're feeding a small batch of data to the neural network through forward propagation and then caculate the accuracy of prediction. We don't want to do this too often as this slows down the overall process. It's important to keep in mind that since we're actually using the model for prediction but not training it, we need to set keep probability for dropout to 1 so we're not losing any connection between neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a single CIFAR-10 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "training one batch took: 0.6824 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0285 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0370 seconds\n",
      "training one batch took: 0.0373 seconds\n",
      "training one batch took: 0.0352 seconds\n",
      "training one batch took: 0.0341 seconds\n",
      "training one batch took: 0.0429 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0373 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0396 seconds\n",
      "training one batch took: 0.0382 seconds\n",
      "training one batch took: 0.0348 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0283 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0280 seconds\n",
      "training one batch took: 0.0280 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0359 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0869 seconds\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     1.6901 Validation Accuracy: 0.320000\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0285 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0395 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0131 seconds\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.3836 Validation Accuracy: 0.425400\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0512 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0360 seconds\n",
      "training one batch took: 0.0356 seconds\n",
      "training one batch took: 0.0351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0349 seconds\n",
      "training one batch took: 0.0350 seconds\n",
      "training one batch took: 0.0365 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0121 seconds\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.1632 Validation Accuracy: 0.447000\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0348 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0349 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0134 seconds\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.9300 Validation Accuracy: 0.501600\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0130 seconds\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.0041 Validation Accuracy: 0.554800\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0391 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0239 seconds\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.0354 Validation Accuracy: 0.577800\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0285 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0335 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0285 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0124 seconds\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.9516 Validation Accuracy: 0.578000\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0342 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0129 seconds\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.8662 Validation Accuracy: 0.600600\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0130 seconds\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.6029 Validation Accuracy: 0.616600\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0149 seconds\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.6775 Validation Accuracy: 0.632400\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0359 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0135 seconds\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.4550 Validation Accuracy: 0.651600\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0286 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0285 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0364 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0129 seconds\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.6766 Validation Accuracy: 0.659000\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0366 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0353 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0346 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0350 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0336 seconds\n",
      "training one batch took: 0.0352 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0152 seconds\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.4148 Validation Accuracy: 0.681800\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0335 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0362 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0354 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0353 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0354 seconds\n",
      "training one batch took: 0.0356 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0371 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0132 seconds\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.4941 Validation Accuracy: 0.683000\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0352 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0390 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0369 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0336 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0362 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0336 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0362 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0335 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0354 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0364 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0331 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0128 seconds\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.2882 Validation Accuracy: 0.692000\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0337 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0153 seconds\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.5020 Validation Accuracy: 0.703000\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0342 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0345 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0378 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0133 seconds\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.1290 Validation Accuracy: 0.685600\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0414 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0370 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0134 seconds\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.4202 Validation Accuracy: 0.708800\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0355 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0335 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0327 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0129 seconds\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.1721 Validation Accuracy: 0.698800\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0288 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0367 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0292 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0143 seconds\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.1702 Validation Accuracy: 0.697800\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0129 seconds\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.0797 Validation Accuracy: 0.713600\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0356 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0351 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0169 seconds\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.0932 Validation Accuracy: 0.705400\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0294 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0134 seconds\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.0544 Validation Accuracy: 0.710600\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0349 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0335 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0336 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0130 seconds\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.1014 Validation Accuracy: 0.712800\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0287 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0128 seconds\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.1232 Validation Accuracy: 0.718200\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0346 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0314 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0355 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0312 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0349 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0128 seconds\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.0432 Validation Accuracy: 0.707400\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0356 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0348 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0357 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0358 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0135 seconds\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.0719 Validation Accuracy: 0.707800\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0289 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0292 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0308 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0316 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0320 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0127 seconds\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.0795 Validation Accuracy: 0.716800\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0328 seconds\n",
      "training one batch took: 0.0358 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0324 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0343 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0356 seconds\n",
      "training one batch took: 0.0348 seconds\n",
      "training one batch took: 0.0329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0336 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0340 seconds\n",
      "training one batch took: 0.0334 seconds\n",
      "training one batch took: 0.0338 seconds\n",
      "training one batch took: 0.0325 seconds\n",
      "training one batch took: 0.0346 seconds\n",
      "training one batch took: 0.0344 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0339 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0352 seconds\n",
      "training one batch took: 0.0306 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0333 seconds\n",
      "training one batch took: 0.0322 seconds\n",
      "training one batch took: 0.0379 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0326 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0305 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0303 seconds\n",
      "training one batch took: 0.0146 seconds\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.0418 Validation Accuracy: 0.718800\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0332 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0299 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0290 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0323 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0294 seconds\n",
      "training one batch took: 0.0313 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0291 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0317 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0310 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0300 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0311 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0297 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0309 seconds\n",
      "training one batch took: 0.0330 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0293 seconds\n",
      "training one batch took: 0.0296 seconds\n",
      "training one batch took: 0.0347 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0304 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0315 seconds\n",
      "training one batch took: 0.0329 seconds\n",
      "training one batch took: 0.0341 seconds\n",
      "training one batch took: 0.0295 seconds\n",
      "training one batch took: 0.0358 seconds\n",
      "training one batch took: 0.0321 seconds\n",
      "training one batch took: 0.0298 seconds\n",
      "training one batch took: 0.0307 seconds\n",
      "training one batch took: 0.0345 seconds\n",
      "training one batch took: 0.0319 seconds\n",
      "training one batch took: 0.0302 seconds\n",
      "training one batch took: 0.0301 seconds\n",
      "training one batch took: 0.0318 seconds\n",
      "training one batch took: 0.0360 seconds\n",
      "training one batch took: 0.0129 seconds\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.0293 Validation Accuracy: 0.714000\n",
      "total took:98.0241 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            batch_mean = np.mean(batch_features)\n",
    "            batch_std = np.std(batch_features)\n",
    "            batch_features = batch_features.astype(np.float32)\n",
    "            for ii in range(batch_features.shape[0]):\n",
    "                batch_features[ii, :, :, :] = (batch_features[ii, :, :, :] - batch_mean) / batch_std  \n",
    "            start = time.time()\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            end = time.time()\n",
    "            print('training one batch took: {:0.4f} seconds'.format(end-start))\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "t2 = time.time()\n",
    "print('total took:{:0.4f} seconds'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     1.8323 Validation Accuracy: 0.260000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.4577 Validation Accuracy: 0.398800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.3267 Validation Accuracy: 0.451000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.2193 Validation Accuracy: 0.479200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.0959 Validation Accuracy: 0.540000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.1388 Validation Accuracy: 0.546000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.0115 Validation Accuracy: 0.582400\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     0.9655 Validation Accuracy: 0.578600\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.0669 Validation Accuracy: 0.626800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.6571 Validation Accuracy: 0.637600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     0.7821 Validation Accuracy: 0.643800\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.6184 Validation Accuracy: 0.670200\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.9592 Validation Accuracy: 0.682000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     0.6973 Validation Accuracy: 0.695400\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.1594 Validation Accuracy: 0.614400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.5221 Validation Accuracy: 0.689200\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.9462 Validation Accuracy: 0.703000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.7341 Validation Accuracy: 0.715800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.7366 Validation Accuracy: 0.730400\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.5306 Validation Accuracy: 0.733800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.7227 Validation Accuracy: 0.726400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.8172 Validation Accuracy: 0.726000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.4045 Validation Accuracy: 0.744000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.5298 Validation Accuracy: 0.723800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.6717 Validation Accuracy: 0.763000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.5980 Validation Accuracy: 0.753800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.3969 Validation Accuracy: 0.764600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.4759 Validation Accuracy: 0.767200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.4950 Validation Accuracy: 0.765600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.5800 Validation Accuracy: 0.769600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.4021 Validation Accuracy: 0.768600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.5002 Validation Accuracy: 0.773600\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.3535 Validation Accuracy: 0.767800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.4576 Validation Accuracy: 0.775200\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.6918 Validation Accuracy: 0.770400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.4263 Validation Accuracy: 0.774600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.3131 Validation Accuracy: 0.781600\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.3416 Validation Accuracy: 0.776400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.2946 Validation Accuracy: 0.773600\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.4671 Validation Accuracy: 0.787400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.2862 Validation Accuracy: 0.777200\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.4996 Validation Accuracy: 0.789600\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.2278 Validation Accuracy: 0.790000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.4307 Validation Accuracy: 0.789800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.3016 Validation Accuracy: 0.793200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.4286 Validation Accuracy: 0.790800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.7071 Validation Accuracy: 0.795200\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.3400 Validation Accuracy: 0.795800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.3728 Validation Accuracy: 0.791000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.3528 Validation Accuracy: 0.801400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.4621 Validation Accuracy: 0.782800\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.3003 Validation Accuracy: 0.804800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.2348 Validation Accuracy: 0.800200\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.3408 Validation Accuracy: 0.811200\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.2887 Validation Accuracy: 0.804800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.3611 Validation Accuracy: 0.794800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.2484 Validation Accuracy: 0.799000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.3716 Validation Accuracy: 0.798200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.2314 Validation Accuracy: 0.803600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.3475 Validation Accuracy: 0.787200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.5382 Validation Accuracy: 0.803400\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.3376 Validation Accuracy: 0.808400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.4127 Validation Accuracy: 0.811800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.1933 Validation Accuracy: 0.807400\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.2549 Validation Accuracy: 0.788000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.2946 Validation Accuracy: 0.799800\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.2288 Validation Accuracy: 0.811000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.2926 Validation Accuracy: 0.815000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.3729 Validation Accuracy: 0.811000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.3057 Validation Accuracy: 0.811800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.2183 Validation Accuracy: 0.801400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.2335 Validation Accuracy: 0.812800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.1602 Validation Accuracy: 0.797000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.1411 Validation Accuracy: 0.814200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.2499 Validation Accuracy: 0.811400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.1264 Validation Accuracy: 0.819000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.1956 Validation Accuracy: 0.815400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.1406 Validation Accuracy: 0.816400\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.1941 Validation Accuracy: 0.813600\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2225 Validation Accuracy: 0.819000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.1574 Validation Accuracy: 0.822400\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.2813 Validation Accuracy: 0.806800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2172 Validation Accuracy: 0.806200\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.2960 Validation Accuracy: 0.807000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.3026 Validation Accuracy: 0.821400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.1728 Validation Accuracy: 0.818600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.2309 Validation Accuracy: 0.817200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.0866 Validation Accuracy: 0.813000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.3771 Validation Accuracy: 0.804000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.1305 Validation Accuracy: 0.814800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.2226 Validation Accuracy: 0.818800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.2163 Validation Accuracy: 0.822000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.1064 Validation Accuracy: 0.819000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.1921 Validation Accuracy: 0.823400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.2126 Validation Accuracy: 0.820200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.0376 Validation Accuracy: 0.811000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.2895 Validation Accuracy: 0.824600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.1515 Validation Accuracy: 0.821400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2303 Validation Accuracy: 0.814800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.1495 Validation Accuracy: 0.821000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.0588 Validation Accuracy: 0.825400\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.2601 Validation Accuracy: 0.819800\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.0861 Validation Accuracy: 0.818400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.0734 Validation Accuracy: 0.824800\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.1287 Validation Accuracy: 0.820000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.0667 Validation Accuracy: 0.818200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.1479 Validation Accuracy: 0.827400\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.1843 Validation Accuracy: 0.822800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.0648 Validation Accuracy: 0.824000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.0593 Validation Accuracy: 0.831600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.1368 Validation Accuracy: 0.823800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.1891 Validation Accuracy: 0.824000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.1106 Validation Accuracy: 0.827600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.1134 Validation Accuracy: 0.830400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.1248 Validation Accuracy: 0.816200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.2035 Validation Accuracy: 0.838600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.0756 Validation Accuracy: 0.826200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.0970 Validation Accuracy: 0.827000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.1729 Validation Accuracy: 0.823000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.0734 Validation Accuracy: 0.827000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.1342 Validation Accuracy: 0.830200\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.1142 Validation Accuracy: 0.829000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.0859 Validation Accuracy: 0.828600\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.1327 Validation Accuracy: 0.822600\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.1185 Validation Accuracy: 0.821200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.1168 Validation Accuracy: 0.821200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.1096 Validation Accuracy: 0.824800\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.0718 Validation Accuracy: 0.829000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.1098 Validation Accuracy: 0.821400\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.0655 Validation Accuracy: 0.827400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.1834 Validation Accuracy: 0.824000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.1373 Validation Accuracy: 0.830600\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.1657 Validation Accuracy: 0.829000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.1166 Validation Accuracy: 0.821800\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.1010 Validation Accuracy: 0.835400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.1383 Validation Accuracy: 0.818400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.0735 Validation Accuracy: 0.822200\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.0801 Validation Accuracy: 0.829800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.0847 Validation Accuracy: 0.821200\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.1181 Validation Accuracy: 0.837800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.0933 Validation Accuracy: 0.832200\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.1000 Validation Accuracy: 0.832400\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.0861 Validation Accuracy: 0.827000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.1246 Validation Accuracy: 0.831800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.1035 Validation Accuracy: 0.824200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.1063 Validation Accuracy: 0.835200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.0696 Validation Accuracy: 0.828400\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.0608 Validation Accuracy: 0.831400\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.0632 Validation Accuracy: 0.833600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.0742 Validation Accuracy: 0.822000\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            \n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                \n",
    "                batch_mean = np.mean(batch_features)\n",
    "                batch_std = np.std(batch_features)\n",
    "                batch_features = batch_features.astype(np.float32)\n",
    "                for ii in range(batch_features.shape[0]):\n",
    "                    batch_features[ii, :, :, :] = (batch_features[ii, :, :, :] - batch_mean) / batch_std \n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.8188291139240507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAJ/CAYAAAB4GhsgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREJLWU7IqIiIhIainZFREREZHU+n+1nIDLiZ7lVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f964c020c18>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    test_features = test_features.astype(np.float32)\n",
    "    batch_mean = np.mean(test_features)\n",
    "    batch_std = np.std(test_features)\n",
    "    for ii in range(test_features.shape[0]):\n",
    "        test_features[ii,:,:,:] = (test_features[ii,:,:,:] - batch_mean) / batch_std\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_1_2]",
   "language": "python",
   "name": "conda-env-tf_1_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
