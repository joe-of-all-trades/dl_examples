{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll build a simple convolutional neural network for CIFAR-10 image classification. Code contained in this project was based on Tensorflow 1.2.1 and python 3.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    \"\"\"\n",
    "    batch_mean = np.mean(x)\n",
    "    batch_std = np.std(x)\n",
    "    x = x.astype(np.float32)\n",
    "    for ii in range(x.shape[0]):\n",
    "        x[ii,:,:,:] = (x[ii,:,:,:] - batch_mean) / batch_std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    smooth_factor = 0.1\n",
    "    output = np.zeros([len(x), 10]) # +( smooth_factor / 9 )\n",
    "    for idx, item in enumerate(x):\n",
    "        output[idx, item] = 1. #- smooth_factor\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above function is equivalent to tf.one_hot(x, 10), but tensorflow module can not be pickled so we're sticking with the above implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "We will randomly shuffle the data, normalize them and save them in binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The above work is all saved so when we're revisiting this notebook we don't have to do those work again. We can start from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import helper\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "valid_features = np.transpose(valid_features,(0, 3, 1, 2))\n",
    "valid_features = normalize(valid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input(n):\n",
    "    return tf.placeholder(tf.float32, None, \"keep_prob_\"+str(n))\n",
    "\n",
    "\n",
    "def neural_net_training_flag():\n",
    "    return tf.placeholder(tf.bool, None, \"train_flag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x_tensor, conv_num_outputs, conv_ksize, conv_strides, is_train):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\", shape=[conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[1], conv_num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    #b = tf.Variable(tf.truncated_normal([conv_num_outputs],\n",
    "    #                                  mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    \n",
    "    wc = tf.nn.conv2d(x_tensor, w, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME', data_format='NCHW')\n",
    "    # z = tf.nn.bias_add(wc, b)\n",
    "    z = tf.layers.batch_normalization(wc, training=is_train)\n",
    "    \n",
    "    return tf.nn.relu(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten layer\n",
    "Implement the flatten function to change the dimension of x_tensor from a 4-D tensor to a 2-D tensor. The output should be the shape (Batch Size, Flattened Image Size). Shortcut option: you can use classes from the TensorFlow Layers or TensorFlow Layers (contrib) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # reference : https://github.com/tensorflow/tensorflow/issues/7253\n",
    "    return tf.reshape(x_tensor, [tf.shape(x_tensor)[0], np.prod(x_tensor.get_shape().as_list()[1:])])\n",
    "    \n",
    "    # This also works\n",
    "    #return tf.reshape(x_tensor, [-1, np.prod(x_tensor.shape[1:]).value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs, is_train):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    fc = tf.reshape(x_tensor, [-1, np.prod(x_tensor.get_shape().as_list()[1:])])\n",
    "    \n",
    "    w = tf.get_variable(\"w\", shape=[np.prod(x_tensor.get_shape().as_list()[1:]), num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    # b = tf.Variable(tf.truncated_normal([num_outputs],mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    z = tf.matmul(fc, w)\n",
    "    z = tf.layers.batch_normalization(z, training=is_train)\n",
    "    \n",
    "    return tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\", shape=[np.prod(x_tensor.get_shape().as_list()[1:]), num_outputs],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.Variable(tf.truncated_normal([num_outputs],mean=0.0, stddev=0.1, dtype=tf.float32))\n",
    "    return tf.add(tf.matmul(x_tensor, w), b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob_1, keep_prob_2, keep_prob_3, keep_prob_4,  train_flag):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convolution and maxpooling layers\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        conv = conv2d(x, 64, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_1)\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        conv = conv2d(conv, 64, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.max_pool(conv, ksize=[1, 1, 2, 2], strides=[1, 1, 2, 2], padding='SAME', data_format='NCHW')\n",
    "    conv = tf.nn.dropout(conv, keep_prob_1)\n",
    "    \n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        conv = conv2d(conv, 128, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_2)\n",
    "    with tf.variable_scope(\"conv4\"):\n",
    "        conv = conv2d(conv, 128, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.max_pool(conv, ksize=[1, 1, 2, 2], strides=[1, 1, 2, 2], padding='SAME', data_format='NCHW')\n",
    "    conv = tf.nn.dropout(conv, keep_prob_2)\n",
    "    \n",
    "    with tf.variable_scope(\"conv5\"):\n",
    "        conv = conv2d(conv, 256, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_3)\n",
    "    with tf.variable_scope(\"conv6\"):\n",
    "        conv = conv2d(conv, 256, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_3)\n",
    "    with tf.variable_scope(\"conv7\"):\n",
    "        conv = conv2d(conv, 256, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.max_pool(conv, ksize=[1, 1, 2, 2], strides=[1, 1, 2, 2], padding='SAME', data_format='NCHW')\n",
    "    conv = tf.nn.dropout(conv, keep_prob_3)\n",
    "    \n",
    "    with tf.variable_scope(\"conv8\"):\n",
    "        conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    with tf.variable_scope(\"conv9\"):\n",
    "        conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    with tf.variable_scope(\"conv10\"):\n",
    "        conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    conv = tf.nn.max_pool(conv, ksize=[1, 1, 2, 2], strides=[1, 1, 2, 2], padding='SAME', data_format='NCHW')\n",
    "    conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    \n",
    "    with tf.variable_scope(\"conv11\"):\n",
    "        conv = conv2d(conv, 512, (1, 1), (1, 1), train_flag)\n",
    "    conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    \n",
    "    \n",
    "    #with tf.variable_scope(\"conv11\"):\n",
    "    #    conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    #conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    #with tf.variable_scope(\"conv12\"):\n",
    "    #    conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    #conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    #with tf.variable_scope(\"conv13\"):\n",
    "    #    conv = conv2d(conv, 512, (3, 3), (1, 1), train_flag)\n",
    "    #conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #conv = tf.nn.dropout(conv, keep_prob_4)\n",
    "    \n",
    "    \n",
    "    # Flatten Layer\n",
    "    f = flatten(conv)\n",
    "\n",
    "    # Fully Connected layers\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "        fc = fully_conn(f, 512, train_flag)\n",
    "        fc = tf.nn.dropout(fc, keep_prob_4)\n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "        fc = fully_conn(fc, 512, train_flag)\n",
    "        fc = tf.nn.dropout(fc, keep_prob_4)\n",
    "    #with tf.variable_scope(\"fc3\"):\n",
    "    #    fc = fully_conn(fc, 512, train_flag)\n",
    "    #    fc = tf.nn.dropout(fc, keep_prob_4)\n",
    "    \n",
    "    # Output Layer\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        o = output(fc, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((3, 32, 32))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob_1 = neural_net_keep_prob_input(1)\n",
    "keep_prob_2 = neural_net_keep_prob_input(2)\n",
    "keep_prob_3 = neural_net_keep_prob_input(3)\n",
    "keep_prob_4 = neural_net_keep_prob_input(4)\n",
    "train_flag = neural_net_training_flag()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob_1, keep_prob_2, keep_prob_3, keep_prob_4, train_flag)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "# Collect batch mean and variance for batch normalization\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, kp1, kp2, kp3, kp4, feature_batch, label_batch, is_train):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, \n",
    "                                      y: label_batch, \n",
    "                                      keep_prob_1: kp1,\n",
    "                                      keep_prob_2: kp2,\n",
    "                                      keep_prob_3: kp3,\n",
    "                                      keep_prob_4: kp4,\n",
    "                                      train_flag:is_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Stats\n",
    "It's important to evaluate the performance of model once in a while. If effect, we're feeding a small batch of data to the neural network through forward propagation and then caculate the accuracy of prediction. We don't want to do this too often as this slows down the overall process. It's important to keep in mind that since we're actually using the model for prediction but not training it, we need to set keep probability for dropout to 1 so we're not losing any connection between neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, \n",
    "                                        y: label_batch, \n",
    "                                        keep_prob_1: 1., \n",
    "                                        keep_prob_2: 1.,\n",
    "                                        keep_prob_3: 1.,\n",
    "                                        keep_prob_4: 1.,\n",
    "                                        train_flag:False})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, \n",
    "                                                 y: valid_labels, \n",
    "                                                 keep_prob_1: 1., \n",
    "                                                 keep_prob_2: 1.,\n",
    "                                                 keep_prob_3: 1.,\n",
    "                                                 keep_prob_4: 1.,\n",
    "                                                 train_flag:False})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "batch_size = 64\n",
    "kp1 = 0.8\n",
    "kp2 = 0.7\n",
    "kp3 = 0.6\n",
    "kp4 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a single CIFAR-10 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('Checking the Training on a Single Batch...')\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "#    for epoch in range(epochs):\n",
    "#        batch_i = 1\n",
    "#        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "#            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, True)\n",
    "#        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "#        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully train the model\n",
    "Deep structure 11 layers, withFliplr, Gaussian Blur, Crop, and Affine, 200 Epochs : 91.1 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0559 Validation Accuracy: 0.195400\n",
      "training one batch took:62.4124 seconds\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.0536 Validation Accuracy: 0.227400\n",
      "training one batch took:57.3689 seconds\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9129 Validation Accuracy: 0.266200\n",
      "training one batch took:57.6723 seconds\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.8352 Validation Accuracy: 0.282200\n",
      "training one batch took:58.2500 seconds\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9180 Validation Accuracy: 0.330800\n",
      "training one batch took:58.8352 seconds\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.4686 Validation Accuracy: 0.354400\n",
      "training one batch took:58.5081 seconds\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.7625 Validation Accuracy: 0.396800\n",
      "training one batch took:58.2588 seconds\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.5576 Validation Accuracy: 0.404000\n",
      "training one batch took:58.4078 seconds\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.5545 Validation Accuracy: 0.478400\n",
      "training one batch took:58.2355 seconds\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.4802 Validation Accuracy: 0.519400\n",
      "training one batch took:59.7029 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-732b4210a385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                                       \u001b[0msometimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                      ], random_order=True)\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 )\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m                     )\n\u001b[1;32m   1082\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 )\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_then_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m             )\n\u001b[1;32m   1547\u001b[0m             result_else_list = self.else_list.augment_images(\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 )\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                     )\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 )\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/imgaug/augmenters.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   3778\u001b[0m                 \u001b[0;31m# values might be mixed with blue values in RGB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0;32m--> 344\u001b[0;31m                               mode, cval, truncate)\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_2/lib/python3.5/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# calculate the kernel:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import helper\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.3, aug)\n",
    "\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        index = np.array(range(n_batches)) + 1\n",
    "        np.random.shuffle(index)\n",
    "        \n",
    "        for batch_i in index: # range(1, n_batches + 1):\n",
    "            \n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                \n",
    "                seq = iaa.Sequential([iaa.Fliplr(0.5),\n",
    "                                      iaa.Flipud(0.2),\n",
    "                                      sometimes(iaa.Crop(px=2)),\n",
    "                                      sometimes(iaa.Affine(scale={\"X\":(0.8,1.2), \"y\":(0.8,1.2)}, \n",
    "                                                           rotate=(-45,45), shear=(-16,16),\n",
    "                                                           translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                                                           cval=(0,255), mode=ia.ALL)),\n",
    "                                      sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.5)),\n",
    "                                      sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "                                      sometimes(iaa.GaussianBlur(sigma=(0, 3.0)))\n",
    "                                     ], random_order=True)\n",
    "                batch_features = seq.augment_images(batch_features)\n",
    "                \n",
    "                batch_features = normalize(batch_features)\n",
    "                \n",
    "                batch_features = np.transpose(batch_features, (0, 3, 1, 2))   \n",
    "                \n",
    "                train_neural_network(sess, optimizer, kp1, kp2, kp3, kp4, batch_features, batch_labels, True)\n",
    "            \n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "        \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "    test_features = np.transpose(test_features,(0, 3, 1, 2))\n",
    "    test_features = normalize(test_features)\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob_1 = loaded_graph.get_tensor_by_name('keep_prob_1:0')\n",
    "        loaded_keep_prob_2 = loaded_graph.get_tensor_by_name('keep_prob_2:0')\n",
    "        loaded_keep_prob_3 = loaded_graph.get_tensor_by_name('keep_prob_3:0')\n",
    "        loaded_keep_prob_4 = loaded_graph.get_tensor_by_name('keep_prob_4:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        loaded_train_flag = loaded_graph.get_tensor_by_name('train_flag:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            \n",
    "            test_batch_acc_total += sess.run(loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, \n",
    "                           loaded_keep_prob_1: 1.0, loaded_keep_prob_2: 1.0,\n",
    "                           loaded_keep_prob_3: 1.0, loaded_keep_prob_4: 1.0,\n",
    "                           loaded_train_flag:False})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        \n",
    "        random_test_predictions = sess.run(tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, \n",
    "                       loaded_keep_prob_1: 1.0, loaded_keep_prob_2: 1.0,\n",
    "                        loaded_keep_prob_3: 1.0, loaded_keep_prob_4: 1.0,\n",
    "                       loaded_train_flag:False})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2x64, 2x128, 3x256, 6x512(keep_prob:0.6), 5 max pooling layer, 300 epochs : 91.1%  \n",
    "2x64, 2x128, 3x256, 6x512, 4 max pooling layer, 300 epochs : 90.9%\n",
    "\n",
    "14 layers, Flipr(0.5), Flipud(0.2), 0.3(crop(2)), 0.3(Affine), 0.3(Gaussian(0,3)), 0.3(GaussianNoise(0,0.05*255),per channel 0.5), 0.3(Multiply(0.8,1.2), 400 epochs: 92%, 1200 epochs : 92.8%, 2000 epochs:93.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_1_2]",
   "language": "python",
   "name": "conda-env-tf_1_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
